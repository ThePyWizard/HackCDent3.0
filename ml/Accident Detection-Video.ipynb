{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c36d8498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from geopy) (2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geocoder in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.38.1)\n",
      "Requirement already satisfied: click in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from geocoder) (8.1.3)\n",
      "Requirement already satisfied: future in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from geocoder) (0.18.3)\n",
      "Requirement already satisfied: ratelim in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from geocoder) (0.1.6)\n",
      "Requirement already satisfied: requests in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from geocoder) (2.28.1)\n",
      "Requirement already satisfied: six in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from geocoder) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from click->geocoder) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ratelim->geocoder) (5.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->geocoder) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->geocoder) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->geocoder) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->geocoder) (2022.9.24)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.21.1 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (1.10.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (9.4.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (2.31.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (23.0)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-image) (0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twilio in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (8.9.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from twilio) (2022.5)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from twilio) (2.28.1)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from twilio) (2.8.0)\n",
      "Requirement already satisfied: aiohttp>=3.8.4 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from twilio) (3.8.4)\n",
      "Requirement already satisfied: aiohttp-retry>=2.8.3 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from twilio) (2.8.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.0.0->twilio) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.0.0->twilio) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.0.0->twilio) (2022.9.24)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install geopy\n",
    "%pip install geocoder\n",
    "%pip install scikit-image\n",
    "%pip install scikit-learn\n",
    "%pip install twilio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c20982",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import cv2     # for capturing videos\n",
    "import math \n",
    "import geocoder\n",
    "import requests\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from twilio.rest import Client\n",
    "from geopy.geocoders import Nominatim\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt \n",
    "from skimage.transform import resize   # for resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d50c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Accidents.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)   # capturing the video from the given path\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "path = \"./traindata/\"\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =path+\"%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1ec509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x233c7fa20a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFHCAYAAACLR7eXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAeS0lEQVR4nO3df2yV9fn/8VdL20NrOS1Q2lKlgMpE5McUtDu6xWQ0VNY4FbKg6ZYqTgOWDZAwqQaY21zJTLbp5nCbG5joZHYRJgzQrsUyZy1QqZYfqzjRNsBpVdJzCkJ/Xp8//HJ/PcKU8qvvc3w+kiuh9/s657wvbjzn5em52zgzMwEAADgkvr83AAAA8FkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgnH4NKE888YRGjRqlgQMHKi8vT9u2bevP7QAAAEf0W0D561//qvvvv1/Lly/XG2+8oUmTJqmgoECtra39tSUAAOCIuP76ZYF5eXm69tpr9dvf/laS1NvbqxEjRugHP/iBlixZ8rm37e3t1cGDBzVo0CDFxcVdiO0CAICzZGZqb29XTk6O4uM//z2ShAu0pwidnZ2qq6tTaWmpdyw+Pl75+fmqqak5qb+jo0MdHR3e1wcOHNC4ceMuyF4BAMC51dzcrEsuueRze/rlWzwffvihenp6lJWVFXE8KytLwWDwpP6ysjKlpaV5RTgBACB6DRo06At7ouIqntLSUoVCIa+am5v7e0sAAOAMnc7HM/rlWzwZGRkaMGCAWlpaIo63tLQoOzv7pH6fzyefz3ehtgcAAPpZv7yDkpSUpMmTJ6uystI71tvbq8rKSgUCgf7YEgAAcEi/vIMiSffff7+Ki4s1ZcoUXXfddfr1r3+to0eP6q677uqvLQEAAEf0W0CZNWuWPvjgAy1btkzBYFBf/epXtXnz5pM+OAsAAL58+u3noJyNcDistLS0/t4GAAA4A6FQSH6//3N7ouIqHgAA8OVCQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHBOnwPK1q1bdfPNNysnJ0dxcXFat25dxLqZadmyZRo+fLiSk5OVn5+vffv2RfQcPnxYRUVF8vv9Sk9P1913360jR46c1SAAACB29DmgHD16VJMmTdITTzxxyvVf/OIXevzxx/Xkk0+qtrZWF110kQoKCnT8+HGvp6ioSLt371ZFRYU2bNigrVu36t577z3zKQAAQGyxsyDJ1q5d633d29tr2dnZ9uijj3rH2trazOfz2XPPPWdmZnv27DFJtn37dq9n06ZNFhcXZwcOHDitxw2FQiaJoiiKoqgorFAo9IWv9ef0Myj79+9XMBhUfn6+dywtLU15eXmqqamRJNXU1Cg9PV1TpkzxevLz8xUfH6/a2tpT3m9HR4fC4XBEAQCA2HVOA0owGJQkZWVlRRzPysry1oLBoDIzMyPWExISNGTIEK/ns8rKypSWlubViBEjzuW2AQCAY6LiKp7S0lKFQiGvmpub+3tLAADgPDqnASU7O1uS1NLSEnG8paXFW8vOzlZra2vEend3tw4fPuz1fJbP55Pf748oAAAQu85pQBk9erSys7NVWVnpHQuHw6qtrVUgEJAkBQIBtbW1qa6uzuupqqpSb2+v8vLyzuV2AABAlEro6w2OHDmid955x/t6//79qq+v15AhQ5Sbm6sFCxboZz/7mcaMGaPRo0dr6dKlysnJ0a233ipJuvLKK3XTTTfpnnvu0ZNPPqmuri7NmzdPt99+u3Jycs7ZYAAAIIqd5hXFni1btpzykqHi4mIz++RS46VLl1pWVpb5fD6bOnWqNTY2RtzHRx99ZHfccYelpqaa3++3u+66y9rb2097D1xmTFEURVHRW6dzmXGcmZmiTDgcVlpaWn9vAwAAnIFQKPSFnyeNiqt4AADAlwsBBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDl9CihlZWW69tprNWjQIGVmZurWW29VY2NjRM/x48dVUlKioUOHKjU1VTNnzlRLS0tET1NTkwoLC5WSkqLMzEwtXrxY3d3dZz8NAACICX0KKNXV1SopKdHrr7+uiooKdXV1adq0aTp69KjXs3DhQq1fv17l5eWqrq7WwYMHNWPGDG+9p6dHhYWF6uzs1Guvvaann35aq1ev1rJly87dVAAAILrZWWhtbTVJVl1dbWZmbW1tlpiYaOXl5V7P3r17TZLV1NSYmdnGjRstPj7egsGg17Ny5Urz+/3W0dFxWo8bCoVMEkVRFEVRUVihUOgLX+vP6jMooVBIkjRkyBBJUl1dnbq6upSfn+/1jB07Vrm5uaqpqZEk1dTUaMKECcrKyvJ6CgoKFA6HtXv37lM+TkdHh8LhcEQBAIDYdcYBpbe3VwsWLNANN9yg8ePHS5KCwaCSkpKUnp4e0ZuVlaVgMOj1fDqcnFg/sXYqZWVlSktL82rEiBFnum0AABAFzjiglJSUaNeuXVqzZs253M8plZaWKhQKedXc3HzeHxMAAPSfhDO50bx587RhwwZt3bpVl1xyiXc8OztbnZ2damtri3gXpaWlRdnZ2V7Ptm3bIu7vxFU+J3o+y+fzyefznclWAQBAFOrTOyhmpnnz5mnt2rWqqqrS6NGjI9YnT56sxMREVVZWescaGxvV1NSkQCAgSQoEAmpoaFBra6vXU1FRIb/fr3Hjxp3NLAAAIFb04aIdmzt3rqWlpdkrr7xihw4d8urjjz/2eubMmWO5ublWVVVlO3bssEAgYIFAwFvv7u628ePH27Rp06y+vt42b95sw4YNs9LS0tPeB1fxUBRFUVT01ulcxdOngPK/HmjVqlVez7Fjx+y+++6zwYMHW0pKit1222126NChiPt57733bPr06ZacnGwZGRm2aNEi6+rqOu19EFAoiqIoKnrrdAJK3P8LHlElHA4rLS2tv7cBAADOQCgUkt/v/9wefhcPAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOX0KKCtXrtTEiRPl9/vl9/sVCAS0adMmb/348eMqKSnR0KFDlZqaqpkzZ6qlpSXiPpqamlRYWKiUlBRlZmZq8eLF6u7uPjfTAACAmNCngHLJJZdoxYoVqqur044dO/TNb35Tt9xyi3bv3i1JWrhwodavX6/y8nJVV1fr4MGDmjFjhnf7np4eFRYWqrOzU6+99pqefvpprV69WsuWLTu3UwEAgOhmZ2nw4MH21FNPWVtbmyUmJlp5ebm3tnfvXpNkNTU1Zma2ceNGi4+Pt2Aw6PWsXLnS/H6/dXR0nPZjhkIhk0RRFEVRVBRWKBT6wtf6M/4MSk9Pj9asWaOjR48qEAiorq5OXV1dys/P93rGjh2r3Nxc1dTUSJJqamo0YcIEZWVleT0FBQUKh8PeuzCn0tHRoXA4HFEAACB29TmgNDQ0KDU1VT6fT3PmzNHatWs1btw4BYNBJSUlKT09PaI/KytLwWBQkhQMBiPCyYn1E2v/S1lZmdLS0rwaMWJEX7cNAACiSJ8DyhVXXKH6+nrV1tZq7ty5Ki4u1p49e87H3jylpaUKhUJeNTc3n9fHAwAA/SuhrzdISkrS5ZdfLkmaPHmytm/frscee0yzZs1SZ2en2traIt5FaWlpUXZ2tiQpOztb27Zti7i/E1f5nOg5FZ/PJ5/P19etAgCAKHXWPwelt7dXHR0dmjx5shITE1VZWemtNTY2qqmpSYFAQJIUCATU0NCg1tZWr6eiokJ+v1/jxo07260AAIBY0YcLdmzJkiVWXV1t+/fvt7feesuWLFlicXFx9vLLL5uZ2Zw5cyw3N9eqqqpsx44dFggELBAIeLfv7u628ePH27Rp06y+vt42b95sw4YNs9LS0r5sg6t4KIqiKCqK63Su4ulTQJk9e7aNHDnSkpKSbNiwYTZ16lQvnJiZHTt2zO677z4bPHiwpaSk2G233WaHDh2KuI/33nvPpk+fbsnJyZaRkWGLFi2yrq6uvmyDgEJRFEVRUVynE1DizMwUZcLhsNLS0vp7GwAA4AyEQiH5/f7P7eF38QAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxzVgFlxYoViouL04IFC7xjx48fV0lJiYYOHarU1FTNnDlTLS0tEbdrampSYWGhUlJSlJmZqcWLF6u7u/tstgIAAGLIGQeU7du36/e//70mTpwYcXzhwoVav369ysvLVV1drYMHD2rGjBneek9PjwoLC9XZ2anXXntNTz/9tFavXq1ly5ad+RQAACC22Blob2+3MWPGWEVFhd144402f/58MzNra2uzxMREKy8v93r37t1rkqympsbMzDZu3Gjx8fEWDAa9npUrV5rf77eOjo7TevxQKGSSKIqiKIqKwgqFQl/4Wn9G76CUlJSosLBQ+fn5Ecfr6urU1dUVcXzs2LHKzc1VTU2NJKmmpkYTJkxQVlaW11NQUKBwOKzdu3ef8vE6OjoUDocjCgAAxK6Evt5gzZo1euONN7R9+/aT1oLBoJKSkpSenh5xPCsrS8Fg0Ov5dDg5sX5i7VTKysr08MMP93WrAAAgSvXpHZTm5mbNnz9fzz77rAYOHHi+9nSS0tJShUIhr5qbmy/YYwMAgAuvTwGlrq5Ora2tuuaaa5SQkKCEhARVV1fr8ccfV0JCgrKystTZ2am2traI27W0tCg7O1uSlJ2dfdJVPSe+PtHzWT6fT36/P6IAAEDs6lNAmTp1qhoaGlRfX+/VlClTVFRU5P05MTFRlZWV3m0aGxvV1NSkQCAgSQoEAmpoaFBra6vXU1FRIb/fr3Hjxp2jsQAAQFTrw8U7p/Tpq3jMzObMmWO5ublWVVVlO3bssEAgYIFAwFvv7u628ePH27Rp06y+vt42b95sw4YNs9LS0tN+TK7ioSiKoqjordO5iqfPH5L9Ir/61a8UHx+vmTNnqqOjQwUFBfrd737nrQ8YMEAbNmzQ3LlzFQgEdNFFF6m4uFg/+clPzvVWAABAlIozM+vvTfRVOBxWWlpaf28DAACcgVAo9IWfJ+V38QAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4JyoDipn19xYAAMAZOp3X8agMKB999FF/bwEAAJyh9vb2L+xJuAD7OOeGDBkiSWpqalJaWlo/7+b8CYfDGjFihJqbm+X3+/t7O+fVl2VW5owtzBlbmPP8MzO1t7crJyfnC3ujMqDEx3/yxk9aWlpM/yM6we/3fynmlL48szJnbGHO2MKc59fpvrEQld/iAQAAsY2AAgAAnBOVAcXn82n58uXy+Xz9vZXz6ssyp/TlmZU5YwtzxhbmdEuccc0uAABwTFS+gwIAAGIbAQUAADiHgAIAAJxDQAEAAM4hoAAAAOdEZUB54oknNGrUKA0cOFB5eXnatm1bf2+pT7Zu3aqbb75ZOTk5iouL07p16yLWzUzLli3T8OHDlZycrPz8fO3bty+i5/DhwyoqKpLf71d6erruvvtuHTly5AJO8fnKysp07bXXatCgQcrMzNStt96qxsbGiJ7jx4+rpKREQ4cOVWpqqmbOnKmWlpaInqamJhUWFiolJUWZmZlavHixuru7L+QoX2jlypWaOHGi91MZA4GANm3a5K3HypyftmLFCsXFxWnBggXesViZ88c//rHi4uIiauzYsd56rMwpSQcOHNB3v/tdDR06VMnJyZowYYJ27NjhrcfCc9GoUaNOOp9xcXEqKSmRFDvns6enR0uXLtXo0aOVnJysyy67TD/96U8jfilf1J1PizJr1qyxpKQk+/Of/2y7d++2e+65x9LT062lpaW/t3baNm7caA899JC98MILJsnWrl0bsb5ixQpLS0uzdevW2Ztvvmnf/va3bfTo0Xbs2DGv56abbrJJkybZ66+/bv/617/s8ssvtzvuuOMCT/K/FRQU2KpVq2zXrl1WX19v3/rWtyw3N9eOHDni9cyZM8dGjBhhlZWVtmPHDvva175m119/vbfe3d1t48ePt/z8fNu5c6dt3LjRMjIyrLS0tD9G+p9efPFF+8c//mFvv/22NTY22oMPPmiJiYm2a9cuM4udOU/Ytm2bjRo1yiZOnGjz58/3jsfKnMuXL7errrrKDh065NUHH3zgrcfKnIcPH7aRI0fanXfeabW1tfbuu+/aSy+9ZO+8847XEwvPRa2trRHnsqKiwiTZli1bzCx2zucjjzxiQ4cOtQ0bNtj+/futvLzcUlNT7bHHHvN6ou18Rl1Aue6666ykpMT7uqenx3JycqysrKwfd3XmPhtQent7LTs72x599FHvWFtbm/l8PnvuuefMzGzPnj0mybZv3+71bNq0yeLi4uzAgQMXbO990draapKsurrazD6ZKTEx0crLy72evXv3miSrqakxs0+CXHx8vAWDQa9n5cqV5vf7raOj48IO0EeDBw+2p556KubmbG9vtzFjxlhFRYXdeOONXkCJpTmXL19ukyZNOuVaLM35wAMP2Ne//vX/uR6rz0Xz58+3yy67zHp7e2PqfBYWFtrs2bMjjs2YMcOKiorMLDrPZ1R9i6ezs1N1dXXKz8/3jsXHxys/P181NTX9uLNzZ//+/QoGgxEzpqWlKS8vz5uxpqZG6enpmjJliteTn5+v+Ph41dbWXvA9n45QKCTp//8m6rq6OnV1dUXMOXbsWOXm5kbMOWHCBGVlZXk9BQUFCofD2r179wXc/enr6enRmjVrdPToUQUCgZibs6SkRIWFhRHzSLF3Pvft26ecnBxdeumlKioqUlNTk6TYmvPFF1/UlClT9J3vfEeZmZm6+uqr9cc//tFbj8Xnos7OTj3zzDOaPXu24uLiYup8Xn/99aqsrNTbb78tSXrzzTf16quvavr06ZKi83xG1W8z/vDDD9XT0xPxD0WSsrKy9J///KefdnVuBYNBSTrljCfWgsGgMjMzI9YTEhI0ZMgQr8clvb29WrBggW644QaNHz9e0iczJCUlKT09PaL3s3Oe6u/hxJpLGhoaFAgEdPz4caWmpmrt2rUaN26c6uvrY2bONWvW6I033tD27dtPWoul85mXl6fVq1friiuu0KFDh/Twww/rG9/4hnbt2hVTc7777rtauXKl7r//fj344IPavn27fvjDHyopKUnFxcUx+Vy0bt06tbW16c4775QUW/9ulyxZonA4rLFjx2rAgAHq6enRI488oqKiIknR+doSVQEF0amkpES7du3Sq6++2t9bOW+uuOIK1dfXKxQK6W9/+5uKi4tVXV3d39s6Z5qbmzV//nxVVFRo4MCB/b2d8+rE/3FK0sSJE5WXl6eRI0fq+eefV3Jycj/u7Nzq7e3VlClT9POf/1ySdPXVV2vXrl168sknVVxc3M+7Oz/+9Kc/afr06crJyenvrZxzzz//vJ599ln95S9/0VVXXaX6+notWLBAOTk5UXs+o+pbPBkZGRowYMBJn7BuaWlRdnZ2P+3q3Doxx+fNmJ2drdbW1oj17u5uHT582Lm/h3nz5mnDhg3asmWLLrnkEu94dna2Ojs71dbWFtH/2TlP9fdwYs0lSUlJuvzyyzV58mSVlZVp0qRJeuyxx2Jmzrq6OrW2tuqaa65RQkKCEhISVF1drccff1wJCQnKysqKiTlPJT09XV/5ylf0zjvvxMz5lKThw4dr3LhxEceuvPJK79tZsfZc9P777+uf//ynvv/973vHYul8Ll68WEuWLNHtt9+uCRMm6Hvf+54WLlyosrIySdF5PqMqoCQlJWny5MmqrKz0jvX29qqyslKBQKAfd3bujB49WtnZ2REzhsNh1dbWejMGAgG1tbWprq7O66mqqlJvb6/y8vIu+J5Pxcw0b948rV27VlVVVRo9enTE+uTJk5WYmBgxZ2Njo5qamiLmbGhoiPgPpqKiQn6//6QnVtf09vaqo6MjZuacOnWqGhoaVF9f79WUKVNUVFTk/TkW5jyVI0eO6L///a+GDx8eM+dTkm644YaTLv1/++23NXLkSEmx81x0wqpVq5SZmanCwkLvWCydz48//ljx8ZEv6QMGDFBvb6+kKD2fF/xjuWdpzZo15vP5bPXq1bZnzx679957LT09PeIT1q5rb2+3nTt32s6dO02S/fKXv7SdO3fa+++/b2afXAqWnp5uf//73+2tt96yW2655ZSXgl199dVWW1trr776qo0ZM8apS/vmzp1raWlp9sorr0Rc4vfxxx97PXPmzLHc3FyrqqqyHTt2WCAQsEAg4K2fuLxv2rRpVl9fb5s3b7Zhw4Y5d3nfkiVLrLq62vbv329vvfWWLVmyxOLi4uzll182s9iZ87M+fRWPWezMuWjRInvllVds//799u9//9vy8/MtIyPDWltbzSx25ty2bZslJCTYI488Yvv27bNnn33WUlJS7JlnnvF6YuG5yOyTqz1zc3PtgQceOGktVs5ncXGxXXzxxd5lxi+88IJlZGTYj370I68n2s5n1AUUM7Pf/OY3lpuba0lJSXbdddfZ66+/3t9b6pMtW7aYpJOquLjYzD65HGzp0qWWlZVlPp/Ppk6dao2NjRH38dFHH9kdd9xhqamp5vf77a677rL29vZ+mObUTjWfJFu1apXXc+zYMbvvvvts8ODBlpKSYrfddpsdOnQo4n7ee+89mz59uiUnJ1tGRoYtWrTIurq6LvA0n2/27Nk2cuRIS0pKsmHDhtnUqVO9cGIWO3N+1mcDSqzMOWvWLBs+fLglJSXZxRdfbLNmzYr42SCxMqeZ2fr16238+PHm8/ls7Nix9oc//CFiPRaei8zMXnrpJZN00t7NYud8hsNhmz9/vuXm5trAgQPt0ksvtYceeijiUuhoO59xZp/6MXMAAAAOiKrPoAAAgC8HAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOOf/AGN4XjKZm9UmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imread('./traindata/0.jpg')   # reading image using its name\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da41986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image_ID  Class\n",
       "0    0.jpg      1\n",
       "1    1.jpg      1\n",
       "2    2.jpg      1\n",
       "3    3.jpg      1\n",
       "4    4.jpg      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('mapping.csv')     # reading the csv file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39a7f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ ]     # creating an empty array\n",
    "tpath=\"traindata/\"\n",
    "for img_name in data.Image_ID:\n",
    "    img = plt.imread(tpath + img_name)\n",
    "    X.append(img)  # storing each image in array X\n",
    "X = np.array(X)    # converting list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8119c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.Class\n",
    "dummy_y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f7cf107",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "for i in range(0,X.shape[0]):\n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
    "    image.append(a)\n",
    "X = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2555ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "X = preprocess_input(X,data_format=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21006e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af20a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d94402",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb02ec43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 11s 2s/step\n",
      "3/3 [==============================] - 4s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((155, 7, 7, 512), (67, 7, 7, 512))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "555111d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(155, 7*7*512)      # converting to 1-D\n",
    "X_valid = X_valid.reshape(67, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a5a6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train/X_train.max()      # centering the data\n",
    "X_valid = X_valid/X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57001716",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "586cff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1024)              25691136  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,693,186\n",
      "Trainable params: 25,693,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e36420f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20e00a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 308ms/step - loss: 0.6663 - accuracy: 0.5935 - val_loss: 0.8542 - val_accuracy: 0.6716\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 1s 261ms/step - loss: 0.3789 - accuracy: 0.8581 - val_loss: 0.9756 - val_accuracy: 0.6716\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.1893 - accuracy: 0.9290 - val_loss: 0.9153 - val_accuracy: 0.7015\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.1258 - accuracy: 0.9677 - val_loss: 0.8221 - val_accuracy: 0.7612\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.0970 - accuracy: 0.9871 - val_loss: 0.8201 - val_accuracy: 0.7910\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.0514 - accuracy: 0.9935 - val_loss: 0.8594 - val_accuracy: 0.7612\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 1s 264ms/step - loss: 0.0444 - accuracy: 0.9935 - val_loss: 0.8373 - val_accuracy: 0.7761\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.8340 - val_accuracy: 0.8060\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.8321 - val_accuracy: 0.8060\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.8530 - val_accuracy: 0.7910\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.8613 - val_accuracy: 0.7910\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.8652 - val_accuracy: 0.7761\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.8720 - val_accuracy: 0.7910\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.8775 - val_accuracy: 0.7910\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.8811 - val_accuracy: 0.7910\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.8829 - val_accuracy: 0.7910\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.8815 - val_accuracy: 0.7910\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.8836 - val_accuracy: 0.8060\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.8887 - val_accuracy: 0.8060\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.8938 - val_accuracy: 0.8060\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8963 - val_accuracy: 0.8060\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9001 - val_accuracy: 0.8060\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9031 - val_accuracy: 0.8060\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.9049 - val_accuracy: 0.8060\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9077 - val_accuracy: 0.8060\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9096 - val_accuracy: 0.8060\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9114 - val_accuracy: 0.8060\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9128 - val_accuracy: 0.8060\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9162 - val_accuracy: 0.8060\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9203 - val_accuracy: 0.8060\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9238 - val_accuracy: 0.8060\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9269 - val_accuracy: 0.8060\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9301 - val_accuracy: 0.8060\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.9309 - val_accuracy: 0.8060\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9324 - val_accuracy: 0.8060\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.9339 - val_accuracy: 0.8060\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9364 - val_accuracy: 0.8060\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9385 - val_accuracy: 0.8060\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9412 - val_accuracy: 0.8060\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9446 - val_accuracy: 0.8060\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9471 - val_accuracy: 0.8060\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9489 - val_accuracy: 0.8060\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9521 - val_accuracy: 0.8060\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9527 - val_accuracy: 0.8060\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9527 - val_accuracy: 0.8060\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9551 - val_accuracy: 0.8060\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9576 - val_accuracy: 0.8060\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.8060\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9610 - val_accuracy: 0.8060\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9636 - val_accuracy: 0.8060\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9654 - val_accuracy: 0.8060\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9670 - val_accuracy: 0.8060\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9692 - val_accuracy: 0.8060\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9709 - val_accuracy: 0.8060\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9720 - val_accuracy: 0.8060\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9735 - val_accuracy: 0.8060\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9743 - val_accuracy: 0.8060\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9760 - val_accuracy: 0.8209\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9780 - val_accuracy: 0.8209\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9790 - val_accuracy: 0.8358\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9808 - val_accuracy: 0.8060\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9831 - val_accuracy: 0.8060\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9855 - val_accuracy: 0.8060\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9861 - val_accuracy: 0.8209\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9872 - val_accuracy: 0.8358\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9891 - val_accuracy: 0.8358\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9917 - val_accuracy: 0.8209\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.8209\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9942 - val_accuracy: 0.8209\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 9.9317e-04 - accuracy: 1.0000 - val_loss: 0.9954 - val_accuracy: 0.8209\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 9.7090e-04 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.8209\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 1s 266ms/step - loss: 9.4566e-04 - accuracy: 1.0000 - val_loss: 0.9983 - val_accuracy: 0.8209\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 1s 264ms/step - loss: 9.2520e-04 - accuracy: 1.0000 - val_loss: 0.9992 - val_accuracy: 0.8358\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 9.0690e-04 - accuracy: 1.0000 - val_loss: 1.0014 - val_accuracy: 0.8209\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 8.8254e-04 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.8209\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 8.6518e-04 - accuracy: 1.0000 - val_loss: 1.0034 - val_accuracy: 0.8209\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 8.4597e-04 - accuracy: 1.0000 - val_loss: 1.0061 - val_accuracy: 0.8358\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 8.2787e-04 - accuracy: 1.0000 - val_loss: 1.0076 - val_accuracy: 0.8358\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 8.1148e-04 - accuracy: 1.0000 - val_loss: 1.0091 - val_accuracy: 0.8209\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 7.9148e-04 - accuracy: 1.0000 - val_loss: 1.0109 - val_accuracy: 0.8209\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 7.7541e-04 - accuracy: 1.0000 - val_loss: 1.0112 - val_accuracy: 0.8358\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 7.5918e-04 - accuracy: 1.0000 - val_loss: 1.0124 - val_accuracy: 0.8358\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 7.4451e-04 - accuracy: 1.0000 - val_loss: 1.0132 - val_accuracy: 0.8209\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 7.2836e-04 - accuracy: 1.0000 - val_loss: 1.0142 - val_accuracy: 0.8209\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 7.1447e-04 - accuracy: 1.0000 - val_loss: 1.0153 - val_accuracy: 0.8358\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 7.0054e-04 - accuracy: 1.0000 - val_loss: 1.0169 - val_accuracy: 0.8358\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 6.8618e-04 - accuracy: 1.0000 - val_loss: 1.0178 - val_accuracy: 0.8209\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 6.7222e-04 - accuracy: 1.0000 - val_loss: 1.0194 - val_accuracy: 0.8209\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 6.6020e-04 - accuracy: 1.0000 - val_loss: 1.0213 - val_accuracy: 0.8209\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 6.4768e-04 - accuracy: 1.0000 - val_loss: 1.0223 - val_accuracy: 0.8358\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 6.3384e-04 - accuracy: 1.0000 - val_loss: 1.0240 - val_accuracy: 0.8358\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 6.2316e-04 - accuracy: 1.0000 - val_loss: 1.0247 - val_accuracy: 0.8209\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 6.1240e-04 - accuracy: 1.0000 - val_loss: 1.0261 - val_accuracy: 0.8358\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 6.0011e-04 - accuracy: 1.0000 - val_loss: 1.0269 - val_accuracy: 0.8358\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 5.8893e-04 - accuracy: 1.0000 - val_loss: 1.0283 - val_accuracy: 0.8358\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 5.7970e-04 - accuracy: 1.0000 - val_loss: 1.0295 - val_accuracy: 0.8358\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 5.7015e-04 - accuracy: 1.0000 - val_loss: 1.0299 - val_accuracy: 0.8358\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 5.5872e-04 - accuracy: 1.0000 - val_loss: 1.0305 - val_accuracy: 0.8358\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 5.4831e-04 - accuracy: 1.0000 - val_loss: 1.0318 - val_accuracy: 0.8358\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 5.3926e-04 - accuracy: 1.0000 - val_loss: 1.0328 - val_accuracy: 0.8358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x233db964940>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "494768fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8d52fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Accident-1.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    path=\"./test/\"\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =path+\"test%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cf0f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9047ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for img_name in test.Image_ID:\n",
    "    img = plt.imread(path + img_name)\n",
    "    test_image.append(img)\n",
    "test_img = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f32558f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for i in range(0,test_img.shape[0]):\n",
    "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
    "    test_image.append(a)\n",
    "test_image = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff1260b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 412ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 7, 7, 512)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing the images\n",
    "test_image = preprocess_input(test_image, data_format=None)\n",
    "\n",
    "# extracting features from the images using pretrained model\n",
    "test_image = base_model.predict(test_image)\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9f69282",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 150528 into shape (9,25088)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\thepywizard\\Documents\\dothack23\\accidentweb3\\ml\\Accident Detection-Video.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/thepywizard/Documents/dothack23/accidentweb3/ml/Accident%20Detection-Video.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_image \u001b[39m=\u001b[39m test_image\u001b[39m.\u001b[39;49mreshape(\u001b[39m9\u001b[39;49m, \u001b[39m7\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m7\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m512\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thepywizard/Documents/dothack23/accidentweb3/ml/Accident%20Detection-Video.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# zero centered images\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thepywizard/Documents/dothack23/accidentweb3/ml/Accident%20Detection-Video.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_image \u001b[39m=\u001b[39m test_image\u001b[39m/\u001b[39mtest_image\u001b[39m.\u001b[39mmax()\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 150528 into shape (9,25088)"
     ]
    }
   ],
   "source": [
    "test_image = test_image.reshape(9, 7*7*512)\n",
    "\n",
    "# zero centered images\n",
    "test_image = test_image/test_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f040ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (0,9):\n",
    "    if predictions[i][0]<predictions[i][1]:\n",
    "        print(\"No Accident\")\n",
    "    else:\n",
    "        print(\"Accident\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoLoc = Nominatim(user_agent=\"GetLoc\")\n",
    "g = geocoder.ip('me')\n",
    "locname = geoLoc.reverse(g.latlng)\n",
    "account_sid = \"ACc2a09b28a2a55c31129cb963048c4024\"\n",
    "auth_token = \"72fa1731b0e3d58c8eab79830e178c49\"\n",
    "client = Client(account_sid, auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b3e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import base64\n",
    "\n",
    "cap = cv2.VideoCapture('Accident-1.mp4')\n",
    "i=0\n",
    "flag=0\n",
    "snapshot_counter = 0\n",
    "imgflag=0\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:  \n",
    "        if predictions[int(i/15)%9][0]<predictions[int(i/15)%9][1]:\n",
    "            percent = predictions[int(i/15)%9][1]*100\n",
    "            predict=\"No Accident\" #+ str(percent)\n",
    "        else:\n",
    "            percent = predictions[int(i/15)%9][0]*100\n",
    "            predict=\"Accident \" + str(percent)\n",
    "            flag=1\n",
    "\n",
    "            if imgflag==0 and percent >80:\n",
    "                AccSnapshotDir = 'AccSnaps/'      \n",
    "                snapshot_filename = f'accident_snapshot_{snapshot_counter}.jpg'\n",
    "                cv2.imwrite(AccSnapshotDir + snapshot_filename, frame)\n",
    "                snapshot_counter += 1\n",
    "                imgflag=1\n",
    "\n",
    "        # Save a snapshot at the time of accident\n",
    "            \n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                predict,\n",
    "                (50, 50),\n",
    "                font, 1,\n",
    "                (0, 255, 255),\n",
    "                3,\n",
    "                cv2.LINE_4)\n",
    "        # cv2.putText(frame,\n",
    "        #         percent,\n",
    "        #         (0, 255, 255),\n",
    "        #         font, 1,\n",
    "        #         (0, 255, 255),\n",
    "        #         3,\n",
    "        #         cv2.LINE_4)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        i=i+1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "if flag==1:\n",
    "    \n",
    "    with open(AccSnapshotDir + snapshot_filename, 'rb') as image_file:\n",
    "        image_binary = image_file.read()\n",
    "    base64_encoded = base64.b64encode(image_binary).decode('utf-8')\n",
    "    # print(locname, datetime.datetime.now(), base64_encoded)\n",
    "    client.messages.create(\n",
    "                 body=\"Accident detected in \"+\"Kochi, Kerala\",\n",
    "                 from_= \"+12568040182\",\n",
    "                 to= \"+919074062399\"\n",
    "                 )\n",
    "    # print(str(datetime.datetime.now().strftime(\"%X\")))\n",
    "    data = {\n",
    "    \"_loc\": \"Kochi, Kerala\",\n",
    "    \"_time\": str(datetime.datetime.now().strftime(\"%X\")),\n",
    "    \"_date\": str(datetime.datetime.now().strftime(\"%x\")),\n",
    "    \"snapShot\": base64_encoded,\n",
    "    \"_plate\" : \"MH 12 1234\"\n",
    "    } \n",
    "    response = requests.post('http://localhost:3000/addAccident', json=data)\n",
    "    if response.status_code == 200:\n",
    "        print(\"POST request successful\")\n",
    "    else:\n",
    "        print(\"POST request failed with status code:\", response.status_code)\n",
    "        print(\"Response content:\", response.text)\n",
    "\n",
    "# release the cap object\n",
    "cap.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a76e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a6a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
